{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdkzimmm/agentic/blob/main/Exa_Company_Analyst.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we will build a company analyst tool for startups that discovers and researches companies building a similar product. If you just want to see the code, check out the [Colab notebook](https://colab.research.google.com/drive/1VROD6zsaDh_rSmogSpSn9FJCwmJO8TSi?here).\n",
        "\n",
        "This project requires an [Exa API key](https://dashboard.exa.ai/overview) and an [OpenAI API key](https://platform.openai.com/api-keys). Get 1000 Exa searches per month free just for [signing up](https://dashboard.exa.ai/overview)!"
      ],
      "metadata": {
        "id": "_B28qUFYx2vd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_1O9xHaLUhp",
        "outputId": "df136285-19f7-49ac-bb1e-ae89a96bb21e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting exa_py\n",
            "  Downloading exa_py-1.0.8-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from exa_py) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->exa_py) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->exa_py) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->exa_py) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->exa_py) (2024.2.2)\n",
            "Installing collected packages: exa_py\n",
            "Successfully installed exa_py-1.0.8\n",
            "Collecting openai\n",
            "  Downloading openai-1.11.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.11.1\n"
          ]
        }
      ],
      "source": [
        "# install Exa and OpenAI SDKs\n",
        "!pip install exa_py\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EXA_API_KEY = \"API_KEY_HERE\"\n",
        "OPENAI_API_KEY =  \"API_KEY_HERE\""
      ],
      "metadata": {
        "id": "g1lcVsjpLlo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Context\n",
        "\n",
        "For this tutorial, let’s use [Thrifthouse](https://thrift.house) as an example company. Let's imagine I'm building Thrifthouse, a platform for selling secondhand goods on college campuses, and I want to learn about other companies doing something similar.\n",
        "\n",
        "Unfortunately, googling “[companies similar to Thrifthouse](https://www.google.com/search?q=companies+similar+to+Thrifthouse)” doesn't do a very good job. Traditional search engines rely heavily on keyword search. In this case we get results about physical thrift stores. Hm, that's not really what I want.\n",
        "\n",
        "Let’s try again, this time searching based on a description of the company, like by googling “[community based resale apps](https://www.google.com/search?q=community+based+resale+apps).” But, this isn’t very helpful either and just returns premade listicles...\n",
        "\n",
        "1. CNBC: Best Selling Apps and Websites for 2024\n",
        "2. CNET: Best Thrifting and Secondhand Shopping Apps of 2024\n",
        "3. Mirror Review: 20 Resale Apps That will Make Your Life Better in 2024\n",
        "4. US News: 15 Best Apps for Buying and Selling Used Stuff\n",
        "\n",
        "What we really need is neural search.\n",
        "\n",
        "### What is Neural vs. Keyword Search\n",
        "Traditional search engines like Google are primarily keyword-based - the core algorithm matches words in a query to text in links. An example of how this is limiting is a search for “companies working on AI for finance”, which returns almost all low-quality listicle results like “[Top 10 companies changing the future of finance with AI](https://aimagazine.com/top10/top-10-companies-changing-the-future-of-finance-with-ai)\" or \"[31 Examples of AI in finance 2024](https://builtin.com/artificial-intelligence/ai-finance-banking-applications-companies)\".\n",
        "\n",
        "With the emergence of LLMs, it’s now possible to build much more intelligent search that is neural - today, that means embeddings-based. That is precisely what Exa is - a fully embeddings-based search engine built using a foundational embeddings model trained for webpage retrieval. It’s capable of understanding entity types (company, blog post, Github repo), descriptors (funny, scholastic, authoritative), and any other semantic qualities inside of a query.\n",
        "\n",
        "\n",
        "### Finding companies with Exa\n",
        "\n",
        "So, let's now try neural search with the Exa Python SDK! We can use the`find_similar_and_contents` python function which first finds similar links, then returns the contents of each link. Our `input_url` is our starting company, <https://thrift.house>  and we set `num_results=10`. This will find 10 webpages semantically similar to Thrifthouse's homepage, which are likely companies similar to Thrifthouse.\n",
        "\n",
        "By specifying `highlights={\"num_sentences\":2}` for each search result, Exa will also identify and return a 2 sentence highlight from the content that's relevant to our query. This will allow us to quickly understand each website that we find.\n"
      ],
      "metadata": {
        "id": "AnQKHB9hx7bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from exa_py import Exa\n",
        "exa = Exa(api_key=EXA_API_KEY)"
      ],
      "metadata": {
        "id": "FrCQgwXdLqlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's get 10 similar companies\n",
        "input_url = 'https://thrift.house'\n",
        "search_response = exa.find_similar_and_contents(\n",
        "        input_url,\n",
        "        highlights={\"num_sentences\":2},\n",
        "        num_results=10)\n",
        "\n",
        "companies = search_response.results\n",
        "\n",
        "print(companies[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lz7VtdpMfqk",
        "outputId": "523b3630-2400-443c-df1f-5d0ba136429e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: rumie - College Marketplace\n",
            "URL: https://www.rumieapp.com/\n",
            "ID: nyGyU_YmvSIIUDRyorci1A\n",
            "Score: 0.7602835893630981\n",
            "Published Date: 2012-01-01\n",
            "Author: None\n",
            "Text: None\n",
            "Highlights: ['It makes buying and selling things so safe and easy! Much more efficient than other buy/sell platforms!Amazing!5 stars for being simple, organized, safe, and a great way to buy and sell in your college community.. much more effective than posting on Facebook or Instagram!The BEST marketplace for college students!!!Once rumie got to my campus, I was excited to see what is has to offer!']\n",
            "Highlight Scores: [0.2570305373890231]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to just see the 10 titles and urls\n",
        "urls = {}\n",
        "for c in companies:\n",
        "  print(c.title + ':' + c.url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1ryegy7M1Or",
        "outputId": "144762f0-5aa1-4c91-cb20-98310a4a8d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rumie - College Marketplace:https://www.rumieapp.com/\n",
            "The Airbnb of Storage:https://www.mystorestash.com/\n",
            "Bunction.net:https://bunction.net/\n",
            "Home - Community Gearbox:https://communitygearbox.com/\n",
            "NOVA SHOPPING:https://www.novashoppingapp.com/\n",
            "Re-Fridge: Buy, sell, or store your college fridge - Re-Fridge:https://www.refridge.com/\n",
            "Jamble: Social Fashion Resale:https://www.jambleapp.com/\n",
            "Branded Resale | Treet:https://www.treet.co/\n",
            "Swapskis:https://www.swapskis.co/\n",
            "Earn Money for Used Clothing:https://www.thredup.com/cleanout?redirectPath=%2Fcleanout%2Fsell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Looks pretty darn good! Now that we have 10 companies we want to dig into further, let’s do some research on each of these companies.\n",
        "\n",
        "### Finding Additional Info for each company\n",
        "\n",
        "Now let's get more information by finding additional webpages about each company. To do this, we're going to do a keyword search of each company's URL. We're using keyword because we want to find webpages that exactly match the company we're inputting. We can do this with the `search_and_contents` function, and specify `type=\"keyword\"` and `num_results=5`. This will give me 5 websites about each company."
      ],
      "metadata": {
        "id": "ds06_gQtyFdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# doing an example with the first company\n",
        "c = companies[0]\n",
        "all_contents = \"\"\n",
        "search_response = exa.search_and_contents(\n",
        "  c.url, # input the company's URL\n",
        "  type=\"keyword\",\n",
        "  num_results=5\n",
        ")\n",
        "research_response = search_response.results\n",
        "for r in research_response:\n",
        "  all_contents += r.text"
      ],
      "metadata": {
        "id": "Axqgp16CNHR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a report\n",
        "\n",
        "Finally, let's create a summarized report that lists our 10 companies and gives us an easily digestible summary of each company."
      ],
      "metadata": {
        "id": "We-N1RbMyMAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "import openai\n",
        "\n",
        "SYSTEM_MESSAGE = \"You are a helpful assistant writing a research report about a company. Summarize the users input into multiple paragraphs. Be extremely concise, professional, and factual as possible. The first paragraph should be an introduction and summary of the company. The second paragraph should include pros and cons of the company. Things like what are they doing well, things they are doing poorly or struggling with. And ideally, suggestions to make the company better.\"\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "completion = openai.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
        "        {\"role\": \"user\", \"content\": all_contents},\n",
        "    ],\n",
        ")\n",
        "\n",
        "summary = completion.choices[0].message.content\n",
        "\n",
        "print(f\"Summary for {c.url}:\")\n",
        "print(textwrap.fill(summary, 80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Thwim2arNajM",
        "outputId": "03798208-1e4d-4628-b017-15f138b01595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for https://www.rumieapp.com/:\n",
            "Rumie is a college-exclusive marketplace app that allows students to buy, sell,\n",
            "and rent items with other students. It has over 320,000 users in its network and\n",
            "offers features such as quick setup, .edu verification, local and campus-wide\n",
            "selling options, and exclusive discounts from local businesses. Students can\n",
            "also rent dresses from other students, buy or sell student tickets at student\n",
            "prices, and enjoy secure and intuitive transactions. The app has received\n",
            "positive feedback from users for its convenience, safety, and effectiveness in\n",
            "buying and selling within the college community.  Pros of Rumie include its\n",
            "focus on college students' needs, such as providing a safe platform and\n",
            "exclusive deals for students. The app offers an intuitive and fast setup\n",
            "process, making it easy for students to start buying and selling. The option to\n",
            "trade with other students is also appreciated. Users find it convenient that\n",
            "they can sell locally or ship items to other campuses. The app's rental\n",
            "guarantee for dresses provides assurance to users that their dresses won't be\n",
            "damaged. Overall, Rumie is highly regarded as a simple, organized, and safe\n",
            "platform for college students to buy and sell within their community.\n",
            "Suggestions to improve Rumie include expanding its reach to more colleges and\n",
            "universities across the nation and eventually internationally. Enhancing\n",
            "marketing efforts and fundraising can aid in raising awareness among college\n",
            "students. Additionally, incorporating features such as improved search filters\n",
            "and a rating/review system for buyers and sellers could enhance the user\n",
            "experience. Continual updates and improvements to the app's interface and\n",
            "functionality can also ensure that it remains user-friendly and efficient.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we’re done! We’ve built an app that takes in a company webpage and uses Exa to\n",
        "\n",
        "1. Discover similar startups\n",
        "2. Find information about each of those startups\n",
        "3. Gather useful content and summarize it with OpenAI\n",
        "\n",
        "Hopefully you found this tutorial helpful and are ready to start building your very own company analyst! Whether you want to generate sales leads or research competitors to your own company, Exa's got you covered :)."
      ],
      "metadata": {
        "id": "_S6blyaJMwUt"
      }
    }
  ]
}